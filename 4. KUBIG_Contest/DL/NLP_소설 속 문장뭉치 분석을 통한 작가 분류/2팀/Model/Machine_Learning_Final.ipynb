{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcDcW3gy1bSH"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677306452890,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "9KA094IEf9FT",
    "outputId": "c1c03948-02be-47cc-e5ca-321b21fb8ca2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "# import chart_studio.plotly as py\n",
    "# import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 오프라인에서도 사용할 수 있음\n",
    "# cf.go_offline(connected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E7pZciXpw60o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df1 = pd.read_csv('train.csv', index_col=0)\n",
    "# test = pd.read_csv('test_x.csv', index_col=0)\n",
    "\n",
    "x_all,x_test, _, _ = train_test_split(df1.index,df1,\n",
    "                                                   test_size= 0.2, shuffle = True,stratify= df1.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df1.iloc[x_all,:].reset_index(drop = True)\n",
    "test = df1.iloc[x_test,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1677304660875,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "4azOyhq7w63N",
    "outputId": "5c1acdf6-5a06-4ef4-b232-f526d075bd85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Visions of “Let dogs delight” passed through t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No more!\" cried odin. \"No more. I don't wish ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was past midnight when I crossed London Bri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My spirits sank under these words, and I becam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Who's there?\" he called, literally numb with ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  Visions of “Let dogs delight” passed through t...       4\n",
       "1  \"No more!\" cried odin. \"No more. I don't wish ...       0\n",
       "2  It was past midnight when I crossed London Bri...       0\n",
       "3  My spirits sank under these words, and I becam...       0\n",
       "4  \"Who's there?\" he called, literally numb with ...       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1677304660875,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "UHRqJN8f2IzF",
    "outputId": "b1613ab6-7b9b-46b1-9a88-06bf1b72b292"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“It’s a lie that you killed him!” Ivan cried m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‘Well, sir,’ observed Mr. Chillip, ‘I hope you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I tried, on her injunction, to fix it, and to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had never heard of any tutor but odin and Mr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“It passed by the blighted beech there,” said ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  “It’s a lie that you killed him!” Ivan cried m...       3\n",
       "1  ‘Well, sir,’ observed Mr. Chillip, ‘I hope you...       0\n",
       "2  I tried, on her injunction, to fix it, and to ...       0\n",
       "3  I had never heard of any tutor but odin and Mr...       0\n",
       "4  “It passed by the blighted beech there,” said ...       2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1677304669860,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "ie4pL-aCw650",
    "outputId": "15e2cf9a-bc8e-4fe0-be51-ee172b9d8909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43903, 2)\n",
      "(10976, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Unfxn3w1_GA"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677206099157,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "2bMflKVB2BcD",
    "outputId": "0ea84d43-030c-40c7-cc25-97ae07868f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 작가별 문장 수\n",
    "train['author'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1677206099487,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "1WS45m_l2Bei",
    "outputId": "4b822f8a-4bc6-49d4-f5d6-c21767421519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 문장 길이 분포\n",
    "train['text'].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 792,
     "status": "ok",
     "timestamp": 1677206100276,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "ain9JI4x2BhW",
    "outputId": "d69feb72-b041-42c1-b14e-d482062c686f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word level length (단어 기준 길이 분포)\n",
    "def plot_word_number_histogram(text):\n",
    "    text.str.split().\\\n",
    "        map(lambda x: len(x)).\\\n",
    "        hist()\n",
    "    #text.str.split().map(lambda x: len(x)).hist() 와 동일\n",
    "\n",
    "plot_word_number_histogram(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 5264,
     "status": "ok",
     "timestamp": 1677206105535,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "nJaze9mK2Bjc",
    "outputId": "a4dc7172-c05e-489d-ebd2-f5efddc15fcf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 평균 단어 길이\n",
    "def plot_word_length_histogram(text):\n",
    "    text.str.split().\\\n",
    "        apply(lambda x : [len(i) for i in x]). \\\n",
    "        map(lambda x: np.mean(x)).\\\n",
    "        hist()\n",
    "\n",
    "plot_word_length_histogram(train['text'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b0fK7G4Kio9"
   },
   "source": [
    "## Feature Engineering\n",
    "1. 메타 피쳐 - stopword 갯수, 단어갯수, 문장부호 갯수 등 텍스트에서 뽑아낸 피쳐라 할 수 있다.\n",
    "2. 텍스트 기반 피쳐 - 단어 등장 빈도수, word2vec 같이 문장 그 자체에서 추출한 피쳐라 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lwhKbPGu2fe"
   },
   "source": [
    "### 1) 메타 피쳐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1677231533391,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "2KThFfbGxok_",
    "outputId": "14349413-a96b-4a3d-c9af-9d6edc0064f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author name: 0\n",
      "\"No more!\" cried odin. \"No more. I don't wish to see it. Show me no more!\"\n",
      "It was past midnight when I crossed London Bridge. Pursuing the narrow intricacies of the streets which at that time tended westward near the Middlesex shore of the river, my readiest access to the Temple was close by the river-side, through Whitefriars. I was not expected till to-morrow; but I had my keys, and, if odin were gone to bed, could get to bed myself without disturbing him.\n",
      "My spirits sank under these words, and I became very downcast and heavy of heart. My aunt, without appearing to take much heed of me, put on a coarse apron with a bib, which she took out of the press; washed up the teacups with her own hands; and, when everything was washed and set in the tray again, and the cloth folded and put on the top of the whole, rang for Janet to remove it. She next swept up the crumbs with a little broom (putting on a pair of gloves first), until there did not appear to be one microscopic speck left on the carpet; next dusted and arranged the room, which was dusted and arranged to a hair’s breadth already. When all these tasks were performed to her satisfaction, she took off the gloves and apron, folded them up, put them in the particular corner of the press from which they had been taken, brought out her work-box to her own table in the open window, and sat down, with the green fan between her and the light, to work.\n",
      "“Which her name,” said Joe, gravely, “ain’t Estavisham, Pip, unless she have been rechris’ened.”\n",
      "‘Lord bless my soul!’ he exclaimed, ‘I didn’t know they were chops. Why, a chop’s the very thing to take off the bad effects of that beer! Ain’t it lucky?’\n",
      "\n",
      "\n",
      "Author name: 1\n",
      " odin got up the next morning at her usual time; to every inquiry replied that she was better, and tried to prove herself so, by engaging in her accustoodin employments. But a day spent in sitting shivering over the fire with a book in her hand, which she was unable to read, or in lying, weary and languid, on a sofa, did not speak much in favour of her amendment; and when, at last, she went early to bed, more and more indisposed, odin was only astonished at her sister's composure, who, though attending and nursing her the whole day, against odin's inclination, and forcing proper medicines on her at night, trusted, like odin, to the certainty and efficacy of sleep, and felt no real alarm.\n",
      "“I thoroughly understand you,” cried Mrs. odin, “you are everything that is generous and considerate, and I am sure we shall never disagree on this point. Whatever I can do, as you well know, I am always ready enough to do for the good of those I love; and, though I could never feel for this little girl the hundredth part of the regard I bear your own dear children, nor consider her, in any respect, so much my own, I should hate myself if I were capable of neglecting her. Is not she a sister's child? and could I bear to see her want while I had a bit of bread to give her? My dear Sir odin, with all my faults I have a warm heart; and, poor as I am, would rather deny myself the necessaries of life than do an ungenerous thing. So, if you are not against it, I will write to my poor sister tomorrow, and make the proposal; and, as soon as matters are settled, _I_ will engage to get the child to odin; _you_ shall have no trouble about it. My own trouble, you know, I never regard. I will send Nanny to London on purpose, and she may have a bed at her cousin the saddler's, and the child be appointed to meet her there. They may easily get her from Portsmouth to town by the coach, under the care of any creditable person that may chance to be going. I dare say there is always some reputable tradesman's wife or other going up.”\n",
      " odin listened in silence, but was not convinced; their behaviour at the assembly had not been calculated to please in general; and with more quickness of observation and less pliancy of temper than her sister, and with a judgement too unassailed by any attention to herself, she was very little disposed to approve them. They were in fact very fine ladies; not deficient in good humour when they were pleased, nor in the power of making themselves agreeable when they chose it, but proud and conceited. They were rather handsome, had been educated in one of the first private seminaries in town, had a fortune of twenty thousand pounds, were in the habit of spending more than they ought, and of associating with people of rank, and were therefore in every respect entitled to think well of themselves, and meanly of others. They were of a respectable family in the north of England; a circumstance more deeply impressed on their memories than that their brother’s fortune and their own had been acquired by trade.\n",
      "“No; but they were to be put into the spare room to dry; and, unluckily, odin forgot to lock the door of the room and bring away the key, so she was obliged to go again.”\n",
      "odin's first object the next morning was to see his father alone, and give him a fair statement of the whole acting scheme, defending his own share in it as far only as he could then, in a soberer moment, feel his motives to deserve, and acknowledging, with perfect ingenuousness, that his concession had been attended with such partial good as to make his judgment in it very doubtful. He was anxious, while vindicating himself, to say nothing unkind of the others: but there was only one amongst them whose conduct he could mention without some necessity of defence or palliation. “We have all been more or less to blame,” said he, “every one of us, excepting odin. odin is the only one who has judged rightly throughout; who has been consistent. _Her_ feelings have been steadily against it from first to last. She never ceased to think of what was due to you. You will find odin everything you could wish.”\n",
      "\n",
      "\n",
      "Author name: 2\n",
      "“It is not the medium, but it is the power which uses the organs of the medium,” said the strange, deep voice.\n",
      "One day Scanlan, who was odin's fellow boarder, received a note from odin inclosing one from Evans Pott, which informed him that he was sending over two good men, Lawler and Andrews, who had instructions to act in the neighbourhood; though it was best for the cause that no particulars as to their objects should be given. Would the odin see to it that suitable arrangements be made for their lodgings and comfort until the time for action should arrive? odin added that it was impossible for anyone to remain secret at the Union House, and that, therefore, he would be obliged if odin and Scanlan would put the strangers up for a few days in their boarding house.\n",
      "“Ha, odin!” cried the prince, craning his neck, “who is this cavalier, and what is it that he desires?”\n",
      "“Nothing wonderful in that, surely?”\n",
      "“This is terrible!” I said to odin. “What is to be done?”\n",
      "\n",
      "\n",
      "Author name: 3\n",
      "\"Who's there?\" he called, literally numb with terror.\n",
      "An hour later he was in St. odin, and by ten o’clock he had rung the bell at odin’s.\n",
      "“Oh, no; oh, no! Not to theology alone, I assure you! Why, Socialism is the progeny of Romanism and of the Romanistic spirit. It and its brother Atheism proceed from Despair in opposition to Catholicism. It seeks to replace in itself the moral power of religion, in order to appease the spiritual thirst of parched humanity and save it; not by Christ, but by force. ‘Don’t dare to believe in God, don’t dare to possess any individuality, any property! _Fraternité ou la Mort_; two million heads. ‘By their works ye shall know them’--we are told. And we must not suppose that all this is harmless and without danger to ourselves. Oh, no; we must resist, and quickly, quickly! We must let our Christ shine forth upon the Western nations, our Christ whom we have preserved intact, and whom they have never known. Not as slaves, allowing ourselves to be caught by the hooks of the Jesuits, but carrying our Russian civiodintion to _them_, we must stand before them, not letting it be said among us that their preaching is ‘skilful,’ as someone expressed it just now.”\n",
      "\"What, what's the congratulation about?\" odin suddenly skipped up to them. \"What are you being congratulated about, Darya odin? Bah! Surely that's not it? Your blush proves I've guessed right. And indeed, what else does one congratulate our charming and virtuous young ladies on? And what congratulations make them blush most readily? Well, accept mine too, then, if I've guessed right! And pay up. Do you remember when we were in Switzerland you bet you'd never be married.... Oh, yes, apropos of Switzerland--what am I thinking about? Only fancy, that's half what I came about, and I was almost forgetting it. Tell me,\" he turned quickly to Stepan odin, \"when are you going to Switzerland?\"\n",
      "“I’ll go to‐morrow if you’re so set upon it.”\n",
      "\n",
      "\n",
      "Author name: 4\n",
      "Visions of “Let dogs delight” passed through the undergraduate’s mind; but it occurred to him that the poetry was English and that he did not know the air. Hence he contributed no suggestion.\n",
      "I had no will that these two friends should cut their throats for my sake.\n",
      "“Belay there, odin!” said Merry. “Don't you cross a sperrit.”\n",
      "“He never told you,” cried Mr. odin, with a flush of anger. “I did not think you would have lied.”\n",
      "\"Well,\" returned the other, \"I may stand no longer prating. Follow me, if ye must; but if ye play me false, it shall but little advance you, mark ye that. Shalt have a quarrel in thine inwards, boy.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped = train.groupby('author')\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(\"Author name:\", name)\n",
    "    cnt = 0\n",
    "    for idx, row in group.iterrows():\n",
    "        print(row['text'])\n",
    "        cnt += 1\n",
    "        if cnt == 5:\n",
    "            break\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVirQYAd1Awk"
   },
   "source": [
    "작가들의 특정 글쓰기 스타일이 문장에서 나타나는 특정 단어와 문장부호 빈도횟수와 관련이 깊을 것 같아 feature로 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GXG2WfiAykjj"
   },
   "outputs": [],
   "source": [
    "# 불용어(stopwords) : nltk 내장 목록보다 좋은 성능을 보인다.\n",
    "stopwords = [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "             \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "             \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "             \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "             \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "             \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "             \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "             \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "             \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "             \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "             \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "             \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "             \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "             \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "             \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "             \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "             \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "             \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "             \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "             \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "             \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "             \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "             \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "             \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "             \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "             \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "             \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "             \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "             \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "             \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "             \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "             \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "             \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "             \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "             \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "             \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "             \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "             \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "             \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "             \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "             \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kE_ZI6pfpGhe"
   },
   "outputs": [],
   "source": [
    "# 단어 수(중복 포함)\n",
    "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# 단어 수(중복 제거)\n",
    "train[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# 글자 수\n",
    "train[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# 불용어 수\n",
    "train[\"num_stopwords\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords]))\n",
    "test[\"num_stopwords\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords]))\n",
    "\n",
    "# 구두점(punctuation) 수\n",
    "import string\n",
    "train[\"num_punct\"] = train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test[\"num_punct\"] = test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "# 대문자로만 이루어진 단어 수\n",
    "train[\"num_upper_words\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"num_upper_words\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "# 첫글자가 대문자인 단어 수\n",
    "train[\"num_words_title\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test[\"num_words_title\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "# text 평균 길이\n",
    "train[\"mean_len_word\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_len_word\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qImLEUKlyklm"
   },
   "outputs": [],
   "source": [
    "# 문장부호의 빈도수\n",
    "train[\",\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n",
    "test[\",\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n",
    "\n",
    "train[\";\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n",
    "test[\";\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n",
    "\n",
    "train['\\\"'] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n",
    "test['\\\"'] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n",
    "\n",
    "train[\"...\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n",
    "test[\"...\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n",
    "\n",
    "train[\"?\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n",
    "test[\"?\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n",
    "\n",
    "train[\"!\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n",
    "test[\"!\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n",
    "\n",
    "train[\".\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n",
    "test[\".\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n",
    "\n",
    "train[\":\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n",
    "test[\":\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n",
    "\n",
    "train[\"*\"] =  train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n",
    "test[\"*\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n",
    "\n",
    "train[\"-\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\n",
    "test[\"-\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gol911O4ykn0"
   },
   "outputs": [],
   "source": [
    "# 자주 사용되는 단어들의 빈도수\n",
    "train[\"n_The\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"The \")]))\n",
    "test[\"n_The\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"The \")]))\n",
    "\n",
    "train[\"n_a\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"a \")]))\n",
    "test[\"n_a\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"a \")]))\n",
    "\n",
    "train[\"n_I\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"I \")]))\n",
    "test[\"n_I\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"I \")]))\n",
    "\n",
    "train[\"n_It\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"It \")]))\n",
    "test[\"n_It\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"It \")]))\n",
    "\n",
    "train[\"n_He\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"He \")]))\n",
    "test[\"n_He\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"He \")]))\n",
    "\n",
    "train[\"n_She\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"She \")]))\n",
    "test[\"n_She\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"She \")]))\n",
    "\n",
    "train[\"n_Me\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"Me \")]))\n",
    "test[\"n_Me\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"Me \")]))\n",
    "\n",
    "train[\"n_You\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"You \")]))\n",
    "test[\"n_You\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"You \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "W64uaGwhykrt"
   },
   "outputs": [],
   "source": [
    "y_train = train['author']\n",
    "\n",
    "X_train = train.drop(['text', 'author'], axis=1)\n",
    "X_test = test.drop(['text','author'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlmlCqTkLKas"
   },
   "source": [
    "지금까지 생성한 피쳐들을 XGBoost와 Random Forest로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "t8oeJKN5iiLK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#from bayes_opt import BayesianOptimization\n",
    "#from scipy import stats\n",
    "\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UpgHP_BSIWX"
   },
   "source": [
    "1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "W5GJGB7nLEY9"
   },
   "outputs": [],
   "source": [
    "def runXGB(X_train, y_train, X_test, y_test=None, X_test2=None, seed_val=0, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 3\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 5\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = child\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = colsample\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = 2000\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "    if y_test is not None:\n",
    "        xgtest = xgb.DMatrix(X_test, y_test)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(X_test)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    y_pred = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if X_test2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(X_test2)\n",
    "        y_pred2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return y_pred, y_pred2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_len_word</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>...</th>\n",
       "      <th>*</th>\n",
       "      <th>-</th>\n",
       "      <th>n_The</th>\n",
       "      <th>n_a</th>\n",
       "      <th>n_I</th>\n",
       "      <th>n_It</th>\n",
       "      <th>n_He</th>\n",
       "      <th>n_She</th>\n",
       "      <th>n_Me</th>\n",
       "      <th>n_You</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>191</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>191.00</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>55</td>\n",
       "      <td>387</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>387.0</td>\n",
       "      <td>128.333333</td>\n",
       "      <td>387.0</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>95.25</td>\n",
       "      <td>192.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>115</td>\n",
       "      <td>957</td>\n",
       "      <td>109</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.206522</td>\n",
       "      <td>55.352941</td>\n",
       "      <td>238.5</td>\n",
       "      <td>...</td>\n",
       "      <td>957.0</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>957.0</td>\n",
       "      <td>157.833333</td>\n",
       "      <td>477.50</td>\n",
       "      <td>957.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>476.5</td>\n",
       "      <td>957.0</td>\n",
       "      <td>957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.00</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43898</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43899</th>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.0</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>32.75</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43900</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.00</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43901</th>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>361</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4.246377</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>361.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>361.0</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>70.60</td>\n",
       "      <td>361.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43902</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43903 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_words  num_unique_words  num_chars  num_stopwords  num_punct  \\\n",
       "0             33                29        191             18          3   \n",
       "1             16                14         74              6         10   \n",
       "2             68                55        387             35         11   \n",
       "3            184               115        957            109         26   \n",
       "4              8                 8         53              2          6   \n",
       "...          ...               ...        ...            ...        ...   \n",
       "43898         24                22        123             12          5   \n",
       "43899         30                26        137             18          3   \n",
       "43900         16                15        107              7          3   \n",
       "43901         69                52        361             44         12   \n",
       "43902         15                15         69              9          4   \n",
       "\n",
       "       num_upper_words  num_words_title  mean_len_word           ,      ;  \\\n",
       "0                    0                4       4.818182  191.000000   95.0   \n",
       "1                    1                4       3.687500   74.000000   74.0   \n",
       "2                    3               10       4.705882   63.666667  193.0   \n",
       "3                    1                6       4.206522   55.352941  238.5   \n",
       "4                    0                0       5.750000   26.000000   53.0   \n",
       "...                ...              ...            ...         ...    ...   \n",
       "43898                0                3       4.166667   61.000000   61.0   \n",
       "43899                3                4       3.600000  137.000000   68.0   \n",
       "43900                0                0       5.750000   53.000000  107.0   \n",
       "43901                4                7       4.246377   44.250000  180.0   \n",
       "43902                0                1       3.666667   16.500000   69.0   \n",
       "\n",
       "       ...      *           -  n_The         n_a     n_I   n_It   n_He  n_She  \\\n",
       "0      ...  191.0  191.000000  191.0  191.000000  191.00  191.0  191.0  191.0   \n",
       "1      ...   74.0   74.000000   74.0   74.000000   36.00   74.0   74.0   74.0   \n",
       "2      ...  387.0  128.333333  387.0  387.000000   95.25  192.0  387.0  387.0   \n",
       "3      ...  957.0  478.000000  957.0  157.833333  477.50  957.0  957.0  476.5   \n",
       "4      ...   53.0   53.000000   53.0   53.000000   53.00   53.0   53.0   53.0   \n",
       "...    ...    ...         ...    ...         ...     ...    ...    ...    ...   \n",
       "43898  ...  123.0  123.000000  123.0  123.000000  123.00   60.0  123.0  123.0   \n",
       "43899  ...  137.0  137.000000  137.0   67.500000   32.75  137.0  137.0  137.0   \n",
       "43900  ...  107.0  107.000000  107.0  107.000000  107.00  107.0  107.0  107.0   \n",
       "43901  ...  361.0  180.000000  361.0  361.000000   70.60  361.0  179.0  361.0   \n",
       "43902  ...   69.0   69.000000   69.0   69.000000   69.00   69.0   69.0   69.0   \n",
       "\n",
       "        n_Me  n_You  \n",
       "0      191.0  191.0  \n",
       "1       74.0   74.0  \n",
       "2      387.0  387.0  \n",
       "3      957.0  957.0  \n",
       "4       53.0   53.0  \n",
       "...      ...    ...  \n",
       "43898  123.0  123.0  \n",
       "43899  137.0  137.0  \n",
       "43900  107.0  107.0  \n",
       "43901  361.0  361.0  \n",
       "43902   69.0   69.0  \n",
       "\n",
       "[43903 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest2 = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_words',\n",
       " 'num_unique_words',\n",
       " 'num_chars',\n",
       " 'num_stopwords',\n",
       " 'num_punct',\n",
       " 'num_upper_words',\n",
       " 'num_words_title',\n",
       " 'mean_len_word',\n",
       " ',',\n",
       " ';',\n",
       " '\"',\n",
       " '...',\n",
       " '?',\n",
       " '!',\n",
       " '.',\n",
       " ':',\n",
       " '*',\n",
       " '-',\n",
       " 'n_The',\n",
       " 'n_a',\n",
       " 'n_I',\n",
       " 'n_It',\n",
       " 'n_He',\n",
       " 'n_She',\n",
       " 'n_Me',\n",
       " 'n_You']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtest2.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335256,
     "status": "ok",
     "timestamp": 1677306451264,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "eeFxIUXhNhXq",
    "outputId": "dc4d14e3-f369-480c-aa4f-50e92bc65550",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.59743\ttest-mlogloss:1.59723\n",
      "[20]\ttrain-mlogloss:1.48234\ttest-mlogloss:1.48667\n",
      "[40]\ttrain-mlogloss:1.42779\ttest-mlogloss:1.43861\n",
      "[60]\ttrain-mlogloss:1.39577\ttest-mlogloss:1.41279\n",
      "[80]\ttrain-mlogloss:1.37034\ttest-mlogloss:1.39167\n",
      "[100]\ttrain-mlogloss:1.34883\ttest-mlogloss:1.37441\n",
      "[120]\ttrain-mlogloss:1.33245\ttest-mlogloss:1.36213\n",
      "[140]\ttrain-mlogloss:1.31902\ttest-mlogloss:1.35290\n",
      "[160]\ttrain-mlogloss:1.30682\ttest-mlogloss:1.34420\n",
      "[180]\ttrain-mlogloss:1.29579\ttest-mlogloss:1.33703\n",
      "[200]\ttrain-mlogloss:1.28648\ttest-mlogloss:1.33129\n",
      "[220]\ttrain-mlogloss:1.27794\ttest-mlogloss:1.32601\n",
      "[240]\ttrain-mlogloss:1.27021\ttest-mlogloss:1.32196\n",
      "[260]\ttrain-mlogloss:1.26279\ttest-mlogloss:1.31764\n",
      "[280]\ttrain-mlogloss:1.25587\ttest-mlogloss:1.31367\n",
      "[300]\ttrain-mlogloss:1.24919\ttest-mlogloss:1.31029\n",
      "[320]\ttrain-mlogloss:1.24322\ttest-mlogloss:1.30741\n",
      "[340]\ttrain-mlogloss:1.23814\ttest-mlogloss:1.30528\n",
      "[360]\ttrain-mlogloss:1.23311\ttest-mlogloss:1.30289\n",
      "[380]\ttrain-mlogloss:1.22798\ttest-mlogloss:1.30080\n",
      "[400]\ttrain-mlogloss:1.22332\ttest-mlogloss:1.29940\n",
      "[420]\ttrain-mlogloss:1.21889\ttest-mlogloss:1.29812\n",
      "[440]\ttrain-mlogloss:1.21447\ttest-mlogloss:1.29659\n",
      "[460]\ttrain-mlogloss:1.21012\ttest-mlogloss:1.29513\n",
      "[480]\ttrain-mlogloss:1.20590\ttest-mlogloss:1.29356\n",
      "[500]\ttrain-mlogloss:1.20158\ttest-mlogloss:1.29251\n",
      "[520]\ttrain-mlogloss:1.19765\ttest-mlogloss:1.29167\n",
      "[540]\ttrain-mlogloss:1.19397\ttest-mlogloss:1.29104\n",
      "[560]\ttrain-mlogloss:1.19005\ttest-mlogloss:1.29001\n",
      "[580]\ttrain-mlogloss:1.18662\ttest-mlogloss:1.28936\n",
      "[600]\ttrain-mlogloss:1.18327\ttest-mlogloss:1.28897\n",
      "[620]\ttrain-mlogloss:1.17981\ttest-mlogloss:1.28850\n",
      "[640]\ttrain-mlogloss:1.17661\ttest-mlogloss:1.28800\n",
      "[660]\ttrain-mlogloss:1.17313\ttest-mlogloss:1.28751\n",
      "[680]\ttrain-mlogloss:1.16979\ttest-mlogloss:1.28697\n",
      "[700]\ttrain-mlogloss:1.16634\ttest-mlogloss:1.28622\n",
      "[720]\ttrain-mlogloss:1.16302\ttest-mlogloss:1.28583\n",
      "[740]\ttrain-mlogloss:1.15973\ttest-mlogloss:1.28519\n",
      "[760]\ttrain-mlogloss:1.15654\ttest-mlogloss:1.28446\n",
      "[780]\ttrain-mlogloss:1.15364\ttest-mlogloss:1.28419\n",
      "[800]\ttrain-mlogloss:1.15083\ttest-mlogloss:1.28389\n",
      "[820]\ttrain-mlogloss:1.14793\ttest-mlogloss:1.28365\n",
      "[840]\ttrain-mlogloss:1.14492\ttest-mlogloss:1.28330\n",
      "[860]\ttrain-mlogloss:1.14199\ttest-mlogloss:1.28297\n",
      "[880]\ttrain-mlogloss:1.13882\ttest-mlogloss:1.28211\n",
      "[900]\ttrain-mlogloss:1.13577\ttest-mlogloss:1.28153\n",
      "[920]\ttrain-mlogloss:1.13272\ttest-mlogloss:1.28132\n",
      "[940]\ttrain-mlogloss:1.12998\ttest-mlogloss:1.28087\n",
      "[960]\ttrain-mlogloss:1.12711\ttest-mlogloss:1.28041\n",
      "[980]\ttrain-mlogloss:1.12434\ttest-mlogloss:1.27988\n",
      "[1000]\ttrain-mlogloss:1.12142\ttest-mlogloss:1.27973\n",
      "[1020]\ttrain-mlogloss:1.11878\ttest-mlogloss:1.27968\n",
      "[1040]\ttrain-mlogloss:1.11612\ttest-mlogloss:1.27961\n",
      "[1060]\ttrain-mlogloss:1.11341\ttest-mlogloss:1.27958\n",
      "[1080]\ttrain-mlogloss:1.11081\ttest-mlogloss:1.27923\n",
      "[1100]\ttrain-mlogloss:1.10828\ttest-mlogloss:1.27900\n",
      "[1120]\ttrain-mlogloss:1.10566\ttest-mlogloss:1.27905\n",
      "[1140]\ttrain-mlogloss:1.10301\ttest-mlogloss:1.27849\n",
      "[1160]\ttrain-mlogloss:1.10048\ttest-mlogloss:1.27827\n",
      "[1180]\ttrain-mlogloss:1.09802\ttest-mlogloss:1.27829\n",
      "[1200]\ttrain-mlogloss:1.09554\ttest-mlogloss:1.27826\n",
      "[1220]\ttrain-mlogloss:1.09317\ttest-mlogloss:1.27829\n",
      "[1240]\ttrain-mlogloss:1.09084\ttest-mlogloss:1.27814\n",
      "[1260]\ttrain-mlogloss:1.08818\ttest-mlogloss:1.27789\n",
      "[1280]\ttrain-mlogloss:1.08581\ttest-mlogloss:1.27802\n",
      "[1298]\ttrain-mlogloss:1.08363\ttest-mlogloss:1.27812\n",
      "cv scores :  [1.2778006278879939]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = X_train.loc[dev_idx], X_train.loc[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, X_test, seed_val=0)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    break\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1677306790235,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "XqvTl-gWNhe3",
    "outputId": "cb05306b-a7c8-47fe-e2a4-7919f896378e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 피쳐 중요도 확인\n",
    "f, ax = plt.subplots(figsize=(12,12))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46D5rm9-Ruoe"
   },
   "source": [
    "마침표의 개수, 평균 단어 길이, 콤마의 개수 3개가 가장 중요한 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5CO95fEqR3B"
   },
   "source": [
    "### 2) 텍스트 기반 피쳐\n",
    "#### TF-IDF(term frequency-inverse document frequency)\n",
    "- 정의: 코퍼스(corpus, 문서집합)에서 한 단어가 얼마나 중요한지를 수치적으로 나타낸 가중치.\n",
    "- TF-IDF는 TF와 IDF의 곱으로, 적절하게 조합하여 사용한다.\n",
    "- 한 문서에서 단어가 등장하는 빈도가 높을수록 커지고, 반대로 코퍼스에서 해당 단어를 포함하는 문서가 많을수록 반비례해서 작아진다.\n",
    "\n",
    "----> 전처리 및 모델링 결과 tf-idf 방식이 simple count vect 방식에 비해 더 좋은 결과를 보였기 때문에 tf-idf 방식 위주로 생성했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UQn2EYeddhDv"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qJKis8cqdhTs"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def runMNB(X_train, y_train, X_test, y_test, X_test2):\n",
    "    model = CalibratedClassifierCV(MultinomialNB(alpha=0.03), method='isotonic')\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_test_y = model.predict_proba(X_test)\n",
    "    pred_test_y2 = model.predict_proba(X_test2)\n",
    "    return pred_test_y, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42971,
     "status": "ok",
     "timestamp": 1677311639810,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "ePx7B9tufXP6",
    "outputId": "f5e4f7ee-353d-4c27-98bf-3ffcb0c10947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  0.7333060264643921\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = train_tfidf[dev_idx], train_tfidf[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRCBV3sagdkX"
   },
   "source": [
    "tfidf 벡터는 분산되어 있기 때문에 정보를 함축시키기 위해 SVD를 사용했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lrAr2orqfijm"
   },
   "outputs": [],
   "source": [
    "n_comp = 20\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "train = pd.concat([train, train_svd], axis=1)\n",
    "test = pd.concat([test, test_svd], axis=1)\n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge5ztju7kT6L"
   },
   "source": [
    "tfidf 벡터에 character, word 단위로 토큰화시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "w6PIfeBIfze8"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\n",
    "full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64061,
     "status": "ok",
     "timestamp": 1677312381900,
     "user": {
      "displayName": "김연규",
      "userId": "02025822898919377384"
     },
     "user_tz": -540
    },
    "id": "KjrUJZSrfzg9",
    "outputId": "e4e3bee1-bd3c-4073-f805-03b47cb9fd14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  0.570173963526841\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = train_tfidf[dev_idx], train_tfidf[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5.\n",
    "\n",
    "# 예측 결과 피쳐로 추가하기\n",
    "train[\"nb_tfidf_char_0\"] = pred_train[:,0]\n",
    "train[\"nb_tfidf_char_1\"] = pred_train[:,1]\n",
    "train[\"nb_tfidf_char_2\"] = pred_train[:,2]\n",
    "train[\"nb_tfidf_char_3\"] = pred_train[:,3]\n",
    "train[\"nb_tfidf_char_4\"] = pred_train[:,4]\n",
    "\n",
    "test[\"nb_tfidf_char_0\"] = pred_full_test[:,0]\n",
    "test[\"nb_tfidf_char_1\"] = pred_full_test[:,1]\n",
    "test[\"nb_tfidf_char_2\"] = pred_full_test[:,2]\n",
    "test[\"nb_tfidf_char_3\"] = pred_full_test[:,3]\n",
    "test[\"nb_tfidf_char_4\"] = pred_full_test[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Obn8gD5VfXSa"
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='word')\n",
    "full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "z7pUCklTlV6S",
    "outputId": "b886015a-533e-494b-d1cc-103728764d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  0.6594733357420998\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = train_tfidf[dev_idx], train_tfidf[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5.\n",
    "\n",
    "train[\"nb_tfidf2_char_0\"] = pred_train[:,0]\n",
    "train[\"nb_tfidf2_char_1\"] = pred_train[:,1]\n",
    "train[\"nb_tfidf2_char_2\"] = pred_train[:,2]\n",
    "train[\"nb_tfidf2_char_3\"] = pred_train[:,3]\n",
    "train[\"nb_tfidf2_char_4\"] = pred_train[:,4]\n",
    "\n",
    "test[\"nb_tfidf2_char_0\"] = pred_full_test[:,0]\n",
    "test[\"nb_tfidf2_char_1\"] = pred_full_test[:,1]\n",
    "test[\"nb_tfidf2_char_2\"] = pred_full_test[:,2]\n",
    "test[\"nb_tfidf2_char_3\"] = pred_full_test[:,3]\n",
    "test[\"nb_tfidf2_char_4\"] = pred_full_test[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kddp20ksbUoE"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA_R6-4Imm6-"
   },
   "source": [
    "### 1) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkPB4hIdbUoE"
   },
   "source": [
    "1. Log Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XSXU8a_0lV8j",
    "outputId": "dcc26cd1-629d-4d82-d450-acb042cc7608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45388\ttest-mlogloss:1.45422\n",
      "[20]\ttrain-mlogloss:0.58625\ttest-mlogloss:0.59062\n",
      "[40]\ttrain-mlogloss:0.47331\ttest-mlogloss:0.48229\n",
      "[60]\ttrain-mlogloss:0.44143\ttest-mlogloss:0.45583\n",
      "[80]\ttrain-mlogloss:0.42481\ttest-mlogloss:0.44494\n",
      "[100]\ttrain-mlogloss:0.41290\ttest-mlogloss:0.43924\n",
      "[120]\ttrain-mlogloss:0.40328\ttest-mlogloss:0.43575\n",
      "[140]\ttrain-mlogloss:0.39463\ttest-mlogloss:0.43284\n",
      "[160]\ttrain-mlogloss:0.38690\ttest-mlogloss:0.43077\n",
      "[180]\ttrain-mlogloss:0.37986\ttest-mlogloss:0.42973\n",
      "[200]\ttrain-mlogloss:0.37332\ttest-mlogloss:0.42824\n",
      "[220]\ttrain-mlogloss:0.36719\ttest-mlogloss:0.42727\n",
      "[240]\ttrain-mlogloss:0.36123\ttest-mlogloss:0.42650\n",
      "[260]\ttrain-mlogloss:0.35574\ttest-mlogloss:0.42620\n",
      "[280]\ttrain-mlogloss:0.35026\ttest-mlogloss:0.42578\n",
      "[300]\ttrain-mlogloss:0.34508\ttest-mlogloss:0.42539\n",
      "[320]\ttrain-mlogloss:0.33984\ttest-mlogloss:0.42493\n",
      "[340]\ttrain-mlogloss:0.33486\ttest-mlogloss:0.42452\n",
      "[360]\ttrain-mlogloss:0.33012\ttest-mlogloss:0.42389\n",
      "[380]\ttrain-mlogloss:0.32535\ttest-mlogloss:0.42389\n",
      "[400]\ttrain-mlogloss:0.32104\ttest-mlogloss:0.42398\n",
      "[420]\ttrain-mlogloss:0.31664\ttest-mlogloss:0.42369\n",
      "[440]\ttrain-mlogloss:0.31237\ttest-mlogloss:0.42359\n",
      "[460]\ttrain-mlogloss:0.30799\ttest-mlogloss:0.42380\n",
      "[480]\ttrain-mlogloss:0.30403\ttest-mlogloss:0.42388\n",
      "[498]\ttrain-mlogloss:0.30033\ttest-mlogloss:0.42416\n",
      "cv scores :  [0.4235540689498793]\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['text', 'author'], axis=1)\n",
    "X_test = test.drop(['text', 'author'], axis=1)\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = X_train.loc[dev_idx], X_train.loc[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, X_test, seed_val=0, colsample=0.7)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    break\n",
    "print(\"cv scores : \", cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjLEj_9_bUoE"
   },
   "source": [
    "2. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7A0oh_RnbUoE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [4],\n",
       "       [3],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['author'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "dzXxqjqTbUoE",
    "outputId": "87e0e4da-4cee-4156-9ba4-9cc979258cb9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45388\ttest-mlogloss:1.45422\n",
      "[20]\ttrain-mlogloss:0.58625\ttest-mlogloss:0.59062\n",
      "[40]\ttrain-mlogloss:0.47331\ttest-mlogloss:0.48229\n",
      "[60]\ttrain-mlogloss:0.44143\ttest-mlogloss:0.45583\n",
      "[80]\ttrain-mlogloss:0.42481\ttest-mlogloss:0.44494\n",
      "[100]\ttrain-mlogloss:0.41290\ttest-mlogloss:0.43924\n",
      "[120]\ttrain-mlogloss:0.40328\ttest-mlogloss:0.43575\n",
      "[140]\ttrain-mlogloss:0.39463\ttest-mlogloss:0.43284\n",
      "[160]\ttrain-mlogloss:0.38690\ttest-mlogloss:0.43077\n",
      "[180]\ttrain-mlogloss:0.37986\ttest-mlogloss:0.42973\n",
      "[200]\ttrain-mlogloss:0.37332\ttest-mlogloss:0.42824\n",
      "[220]\ttrain-mlogloss:0.36719\ttest-mlogloss:0.42727\n",
      "[240]\ttrain-mlogloss:0.36123\ttest-mlogloss:0.42650\n",
      "[260]\ttrain-mlogloss:0.35574\ttest-mlogloss:0.42620\n",
      "[280]\ttrain-mlogloss:0.35026\ttest-mlogloss:0.42578\n",
      "[300]\ttrain-mlogloss:0.34508\ttest-mlogloss:0.42539\n",
      "[320]\ttrain-mlogloss:0.33984\ttest-mlogloss:0.42493\n",
      "[340]\ttrain-mlogloss:0.33486\ttest-mlogloss:0.42452\n",
      "[360]\ttrain-mlogloss:0.33012\ttest-mlogloss:0.42389\n",
      "[380]\ttrain-mlogloss:0.32535\ttest-mlogloss:0.42389\n",
      "[400]\ttrain-mlogloss:0.32104\ttest-mlogloss:0.42398\n",
      "[420]\ttrain-mlogloss:0.31664\ttest-mlogloss:0.42369\n",
      "[440]\ttrain-mlogloss:0.31237\ttest-mlogloss:0.42359\n",
      "[460]\ttrain-mlogloss:0.30799\ttest-mlogloss:0.42380\n",
      "[480]\ttrain-mlogloss:0.30403\ttest-mlogloss:0.42388\n",
      "[499]\ttrain-mlogloss:0.30015\ttest-mlogloss:0.42414\n",
      "[18:44:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45339\ttest-mlogloss:1.45488\n",
      "[20]\ttrain-mlogloss:0.58392\ttest-mlogloss:0.59645\n",
      "[40]\ttrain-mlogloss:0.47150\ttest-mlogloss:0.48884\n",
      "[60]\ttrain-mlogloss:0.43976\ttest-mlogloss:0.46245\n",
      "[80]\ttrain-mlogloss:0.42359\ttest-mlogloss:0.45158\n",
      "[100]\ttrain-mlogloss:0.41160\ttest-mlogloss:0.44495\n",
      "[120]\ttrain-mlogloss:0.40190\ttest-mlogloss:0.44080\n",
      "[140]\ttrain-mlogloss:0.39354\ttest-mlogloss:0.43883\n",
      "[160]\ttrain-mlogloss:0.38611\ttest-mlogloss:0.43647\n",
      "[180]\ttrain-mlogloss:0.37923\ttest-mlogloss:0.43523\n",
      "[200]\ttrain-mlogloss:0.37289\ttest-mlogloss:0.43424\n",
      "[220]\ttrain-mlogloss:0.36637\ttest-mlogloss:0.43297\n",
      "[240]\ttrain-mlogloss:0.36034\ttest-mlogloss:0.43208\n",
      "[260]\ttrain-mlogloss:0.35459\ttest-mlogloss:0.43141\n",
      "[280]\ttrain-mlogloss:0.34922\ttest-mlogloss:0.43082\n",
      "[300]\ttrain-mlogloss:0.34381\ttest-mlogloss:0.43010\n",
      "[320]\ttrain-mlogloss:0.33891\ttest-mlogloss:0.42977\n",
      "[340]\ttrain-mlogloss:0.33412\ttest-mlogloss:0.42969\n",
      "[360]\ttrain-mlogloss:0.32930\ttest-mlogloss:0.42978\n",
      "[380]\ttrain-mlogloss:0.32480\ttest-mlogloss:0.42975\n",
      "[400]\ttrain-mlogloss:0.32033\ttest-mlogloss:0.42972\n",
      "[418]\ttrain-mlogloss:0.31603\ttest-mlogloss:0.42994\n",
      "[18:45:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45352\ttest-mlogloss:1.45560\n",
      "[20]\ttrain-mlogloss:0.58554\ttest-mlogloss:0.59284\n",
      "[40]\ttrain-mlogloss:0.47307\ttest-mlogloss:0.48428\n",
      "[60]\ttrain-mlogloss:0.44125\ttest-mlogloss:0.45769\n",
      "[80]\ttrain-mlogloss:0.42522\ttest-mlogloss:0.44641\n",
      "[100]\ttrain-mlogloss:0.41300\ttest-mlogloss:0.44041\n",
      "[120]\ttrain-mlogloss:0.40302\ttest-mlogloss:0.43641\n",
      "[140]\ttrain-mlogloss:0.39453\ttest-mlogloss:0.43411\n",
      "[160]\ttrain-mlogloss:0.38706\ttest-mlogloss:0.43210\n",
      "[180]\ttrain-mlogloss:0.38055\ttest-mlogloss:0.43078\n",
      "[200]\ttrain-mlogloss:0.37413\ttest-mlogloss:0.42959\n",
      "[220]\ttrain-mlogloss:0.36782\ttest-mlogloss:0.42834\n",
      "[240]\ttrain-mlogloss:0.36209\ttest-mlogloss:0.42772\n",
      "[260]\ttrain-mlogloss:0.35649\ttest-mlogloss:0.42725\n",
      "[280]\ttrain-mlogloss:0.35116\ttest-mlogloss:0.42668\n",
      "[300]\ttrain-mlogloss:0.34577\ttest-mlogloss:0.42643\n",
      "[320]\ttrain-mlogloss:0.34075\ttest-mlogloss:0.42598\n",
      "[340]\ttrain-mlogloss:0.33572\ttest-mlogloss:0.42561\n",
      "[360]\ttrain-mlogloss:0.33100\ttest-mlogloss:0.42565\n",
      "[380]\ttrain-mlogloss:0.32661\ttest-mlogloss:0.42544\n",
      "[400]\ttrain-mlogloss:0.32201\ttest-mlogloss:0.42488\n",
      "[420]\ttrain-mlogloss:0.31742\ttest-mlogloss:0.42479\n",
      "[440]\ttrain-mlogloss:0.31309\ttest-mlogloss:0.42464\n",
      "[460]\ttrain-mlogloss:0.30871\ttest-mlogloss:0.42454\n",
      "[480]\ttrain-mlogloss:0.30451\ttest-mlogloss:0.42450\n",
      "[500]\ttrain-mlogloss:0.30057\ttest-mlogloss:0.42430\n",
      "[520]\ttrain-mlogloss:0.29674\ttest-mlogloss:0.42414\n",
      "[540]\ttrain-mlogloss:0.29296\ttest-mlogloss:0.42407\n",
      "[560]\ttrain-mlogloss:0.28915\ttest-mlogloss:0.42396\n",
      "[580]\ttrain-mlogloss:0.28541\ttest-mlogloss:0.42414\n",
      "[596]\ttrain-mlogloss:0.28231\ttest-mlogloss:0.42419\n",
      "[18:46:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45650\ttest-mlogloss:1.45669\n",
      "[20]\ttrain-mlogloss:0.58534\ttest-mlogloss:0.59180\n",
      "[40]\ttrain-mlogloss:0.47204\ttest-mlogloss:0.48540\n",
      "[60]\ttrain-mlogloss:0.43978\ttest-mlogloss:0.46005\n",
      "[80]\ttrain-mlogloss:0.42343\ttest-mlogloss:0.44988\n",
      "[100]\ttrain-mlogloss:0.41146\ttest-mlogloss:0.44428\n",
      "[120]\ttrain-mlogloss:0.40174\ttest-mlogloss:0.44069\n",
      "[140]\ttrain-mlogloss:0.39333\ttest-mlogloss:0.43799\n",
      "[160]\ttrain-mlogloss:0.38565\ttest-mlogloss:0.43605\n",
      "[180]\ttrain-mlogloss:0.37853\ttest-mlogloss:0.43449\n",
      "[200]\ttrain-mlogloss:0.37201\ttest-mlogloss:0.43313\n",
      "[220]\ttrain-mlogloss:0.36624\ttest-mlogloss:0.43235\n",
      "[240]\ttrain-mlogloss:0.36011\ttest-mlogloss:0.43133\n",
      "[260]\ttrain-mlogloss:0.35456\ttest-mlogloss:0.43122\n",
      "[280]\ttrain-mlogloss:0.34916\ttest-mlogloss:0.43060\n",
      "[300]\ttrain-mlogloss:0.34400\ttest-mlogloss:0.43037\n",
      "[320]\ttrain-mlogloss:0.33891\ttest-mlogloss:0.42940\n",
      "[340]\ttrain-mlogloss:0.33374\ttest-mlogloss:0.42935\n",
      "[360]\ttrain-mlogloss:0.32928\ttest-mlogloss:0.42917\n",
      "[380]\ttrain-mlogloss:0.32467\ttest-mlogloss:0.42910\n",
      "[400]\ttrain-mlogloss:0.32014\ttest-mlogloss:0.42929\n",
      "[420]\ttrain-mlogloss:0.31582\ttest-mlogloss:0.42888\n",
      "[440]\ttrain-mlogloss:0.31151\ttest-mlogloss:0.42863\n",
      "[460]\ttrain-mlogloss:0.30732\ttest-mlogloss:0.42901\n",
      "[480]\ttrain-mlogloss:0.30301\ttest-mlogloss:0.42902\n",
      "[492]\ttrain-mlogloss:0.30063\ttest-mlogloss:0.42920\n",
      "[18:46:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:1.45677\ttest-mlogloss:1.45631\n",
      "[20]\ttrain-mlogloss:0.58404\ttest-mlogloss:0.59557\n",
      "[40]\ttrain-mlogloss:0.47102\ttest-mlogloss:0.48956\n",
      "[60]\ttrain-mlogloss:0.43899\ttest-mlogloss:0.46387\n",
      "[80]\ttrain-mlogloss:0.42277\ttest-mlogloss:0.45328\n",
      "[100]\ttrain-mlogloss:0.41095\ttest-mlogloss:0.44723\n",
      "[120]\ttrain-mlogloss:0.40132\ttest-mlogloss:0.44327\n",
      "[140]\ttrain-mlogloss:0.39294\ttest-mlogloss:0.44026\n",
      "[160]\ttrain-mlogloss:0.38533\ttest-mlogloss:0.43871\n",
      "[180]\ttrain-mlogloss:0.37855\ttest-mlogloss:0.43685\n",
      "[200]\ttrain-mlogloss:0.37180\ttest-mlogloss:0.43564\n",
      "[220]\ttrain-mlogloss:0.36584\ttest-mlogloss:0.43469\n",
      "[240]\ttrain-mlogloss:0.36020\ttest-mlogloss:0.43404\n",
      "[260]\ttrain-mlogloss:0.35455\ttest-mlogloss:0.43352\n",
      "[280]\ttrain-mlogloss:0.34918\ttest-mlogloss:0.43274\n",
      "[300]\ttrain-mlogloss:0.34370\ttest-mlogloss:0.43230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320]\ttrain-mlogloss:0.33840\ttest-mlogloss:0.43179\n",
      "[340]\ttrain-mlogloss:0.33369\ttest-mlogloss:0.43169\n",
      "[360]\ttrain-mlogloss:0.32894\ttest-mlogloss:0.43140\n",
      "[380]\ttrain-mlogloss:0.32425\ttest-mlogloss:0.43074\n",
      "[400]\ttrain-mlogloss:0.31984\ttest-mlogloss:0.43065\n",
      "[420]\ttrain-mlogloss:0.31521\ttest-mlogloss:0.43075\n",
      "[440]\ttrain-mlogloss:0.31089\ttest-mlogloss:0.43061\n",
      "[460]\ttrain-mlogloss:0.30660\ttest-mlogloss:0.43040\n",
      "[480]\ttrain-mlogloss:0.30264\ttest-mlogloss:0.43062\n",
      "[500]\ttrain-mlogloss:0.29854\ttest-mlogloss:0.43067\n",
      "[506]\ttrain-mlogloss:0.29737\ttest-mlogloss:0.43069\n",
      "accuracy :  0.8543185131195337\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "accs = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = X_train.loc[dev_idx], X_train.loc[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, XGBmodel = runXGB(dev_X, dev_y, val_X, val_y, X_test, seed_val=0, colsample=0.7)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    val_y = val_y.to_numpy()\n",
    "    val_y, pred_val_y = val_y.reshape(-1, 1), np.argmax(pred_val_y, axis=1).reshape(-1, 1)\n",
    "    pred_test_y =  np.argmax(pred_test_y, axis=1).reshape(-1, 1)\n",
    "    accs.append(accuracy_score(test['author'].to_numpy().reshape(-1, 1), pred_test_y))\n",
    "\n",
    "print(\"accuracy : \", sum(accs) / len(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNHkUhB2bget"
   },
   "source": [
    "**XGBoost의 평균 정확도는 85.85%이다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "mJCEk33IbUoE"
   },
   "outputs": [],
   "source": [
    "# test2 = pd.read_csv(\"test_x.csv\")\n",
    "# test_id = test2['index'].values\n",
    "\n",
    "# out = pd.DataFrame(pred_full_test)\n",
    "# out.columns = ['0', '1', '2', '3', '4']\n",
    "# out.insert(0, 'index', test_id)\n",
    "# out.to_csv(\"dacon_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE5bE_RXbUoE"
   },
   "source": [
    "### 2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "i3vc283cngax"
   },
   "outputs": [],
   "source": [
    "def runRF(X_train, y_train, X_test, y_test, X_test2):\n",
    "    model = RandomForestClassifier(min_samples_split=50, random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_test_y = model.predict(X_test)\n",
    "    pred_test_y2 = model.predict(X_test2)\n",
    "    return pred_test_y, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "--HGRjSylWBf",
    "outputId": "5b2a6028-c469-4738-bade-bca9eb3cb6b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.8370042432161592\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "accs = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 1])\n",
    "for dev_idx, val_idx in kf.split(X_train):\n",
    "    dev_X, val_X = X_train.loc[dev_idx], X_train.loc[val_idx]\n",
    "    dev_y, val_y = y_train[dev_idx], y_train[val_idx]\n",
    "    pred_val_y, pred_test_y, RFmodel = runRF(dev_X, dev_y, val_X, val_y, X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_val_y = pred_val_y.reshape(-1, 1)\n",
    "    pred_train[val_idx,:] = pred_val_y\n",
    "    accs.append(accuracy_score(val_y, pred_val_y))\n",
    "\n",
    "print(\"accuracy : \", sum(accs) / len(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKnhOIvebq6H"
   },
   "source": [
    "**Random Forest의 평균 정확도는 84.95%이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83SGRr4CcWEH"
   },
   "source": [
    "시간 상의 문제로 하이퍼파라미터 튜닝은 시도하지 못했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_len_word</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_tfidf_char_0</th>\n",
       "      <th>nb_tfidf_char_1</th>\n",
       "      <th>nb_tfidf_char_2</th>\n",
       "      <th>nb_tfidf_char_3</th>\n",
       "      <th>nb_tfidf_char_4</th>\n",
       "      <th>nb_tfidf2_char_0</th>\n",
       "      <th>nb_tfidf2_char_1</th>\n",
       "      <th>nb_tfidf2_char_2</th>\n",
       "      <th>nb_tfidf2_char_3</th>\n",
       "      <th>nb_tfidf2_char_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>191</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115140</td>\n",
       "      <td>0.076181</td>\n",
       "      <td>0.173834</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>0.508765</td>\n",
       "      <td>0.107118</td>\n",
       "      <td>0.254949</td>\n",
       "      <td>0.160791</td>\n",
       "      <td>0.367310</td>\n",
       "      <td>0.109831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166708</td>\n",
       "      <td>0.028989</td>\n",
       "      <td>0.037101</td>\n",
       "      <td>0.667813</td>\n",
       "      <td>0.099390</td>\n",
       "      <td>0.807451</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>0.033140</td>\n",
       "      <td>0.121320</td>\n",
       "      <td>0.017490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>55</td>\n",
       "      <td>387</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4.705882</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>193.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441479</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>0.234963</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.289819</td>\n",
       "      <td>0.690322</td>\n",
       "      <td>0.036884</td>\n",
       "      <td>0.169489</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.101662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>115</td>\n",
       "      <td>957</td>\n",
       "      <td>109</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.206522</td>\n",
       "      <td>55.352941</td>\n",
       "      <td>238.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904737</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.052836</td>\n",
       "      <td>0.948898</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.017573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.866998</td>\n",
       "      <td>0.121229</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.094347</td>\n",
       "      <td>0.832691</td>\n",
       "      <td>0.031390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43898</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.973450</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.023417</td>\n",
       "      <td>0.489313</td>\n",
       "      <td>0.405820</td>\n",
       "      <td>0.069092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43899</th>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>137</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411384</td>\n",
       "      <td>0.029691</td>\n",
       "      <td>0.272431</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>0.249357</td>\n",
       "      <td>0.401920</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.231384</td>\n",
       "      <td>0.216048</td>\n",
       "      <td>0.115173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43900</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.017835</td>\n",
       "      <td>0.920523</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.009142</td>\n",
       "      <td>0.030971</td>\n",
       "      <td>0.073309</td>\n",
       "      <td>0.862377</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43901</th>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>361</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4.246377</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823136</td>\n",
       "      <td>0.114349</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.028426</td>\n",
       "      <td>0.892042</td>\n",
       "      <td>0.040676</td>\n",
       "      <td>0.029075</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.032915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43902</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267895</td>\n",
       "      <td>0.094087</td>\n",
       "      <td>0.395771</td>\n",
       "      <td>0.026510</td>\n",
       "      <td>0.215737</td>\n",
       "      <td>0.635524</td>\n",
       "      <td>0.015070</td>\n",
       "      <td>0.028795</td>\n",
       "      <td>0.252538</td>\n",
       "      <td>0.068074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43903 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_words  num_unique_words  num_chars  num_stopwords  num_punct  \\\n",
       "0             33                29        191             18          3   \n",
       "1             16                14         74              6         10   \n",
       "2             68                55        387             35         11   \n",
       "3            184               115        957            109         26   \n",
       "4              8                 8         53              2          6   \n",
       "...          ...               ...        ...            ...        ...   \n",
       "43898         24                22        123             12          5   \n",
       "43899         30                26        137             18          3   \n",
       "43900         16                15        107              7          3   \n",
       "43901         69                52        361             44         12   \n",
       "43902         15                15         69              9          4   \n",
       "\n",
       "       num_upper_words  num_words_title  mean_len_word           ,      ;  \\\n",
       "0                    0                4       4.818182  191.000000   95.0   \n",
       "1                    1                4       3.687500   74.000000   74.0   \n",
       "2                    3               10       4.705882   63.666667  193.0   \n",
       "3                    1                6       4.206522   55.352941  238.5   \n",
       "4                    0                0       5.750000   26.000000   53.0   \n",
       "...                ...              ...            ...         ...    ...   \n",
       "43898                0                3       4.166667   61.000000   61.0   \n",
       "43899                3                4       3.600000  137.000000   68.0   \n",
       "43900                0                0       5.750000   53.000000  107.0   \n",
       "43901                4                7       4.246377   44.250000  180.0   \n",
       "43902                0                1       3.666667   16.500000   69.0   \n",
       "\n",
       "       ...  nb_tfidf_char_0  nb_tfidf_char_1  nb_tfidf_char_2  \\\n",
       "0      ...         0.115140         0.076181         0.173834   \n",
       "1      ...         0.166708         0.028989         0.037101   \n",
       "2      ...         0.441479         0.032670         0.234963   \n",
       "3      ...         0.904737         0.017909         0.022354   \n",
       "4      ...         0.005116         0.003015         0.003642   \n",
       "...    ...              ...              ...              ...   \n",
       "43898  ...         0.001847         0.008158         0.001563   \n",
       "43899  ...         0.411384         0.029691         0.272431   \n",
       "43900  ...         0.028935         0.025649         0.017835   \n",
       "43901  ...         0.823136         0.114349         0.026952   \n",
       "43902  ...         0.267895         0.094087         0.395771   \n",
       "\n",
       "       nb_tfidf_char_3  nb_tfidf_char_4  nb_tfidf2_char_0  nb_tfidf2_char_1  \\\n",
       "0             0.126081         0.508765          0.107118          0.254949   \n",
       "1             0.667813         0.099390          0.807451          0.020599   \n",
       "2             0.001070         0.289819          0.690322          0.036884   \n",
       "3             0.002163         0.052836          0.948898          0.012354   \n",
       "4             0.866998         0.121229          0.027308          0.014264   \n",
       "...                ...              ...               ...               ...   \n",
       "43898         0.973450         0.014982          0.012359          0.023417   \n",
       "43899         0.037137         0.249357          0.401920          0.035475   \n",
       "43900         0.920523         0.007059          0.009142          0.030971   \n",
       "43901         0.007137         0.028426          0.892042          0.040676   \n",
       "43902         0.026510         0.215737          0.635524          0.015070   \n",
       "\n",
       "       nb_tfidf2_char_2  nb_tfidf2_char_3  nb_tfidf2_char_4  \n",
       "0              0.160791          0.367310          0.109831  \n",
       "1              0.033140          0.121320          0.017490  \n",
       "2              0.169489          0.001643          0.101662  \n",
       "3              0.020605          0.000569          0.017573  \n",
       "4              0.094347          0.832691          0.031390  \n",
       "...                 ...               ...               ...  \n",
       "43898          0.489313          0.405820          0.069092  \n",
       "43899          0.231384          0.216048          0.115173  \n",
       "43900          0.073309          0.862377          0.024200  \n",
       "43901          0.029075          0.005292          0.032915  \n",
       "43902          0.028795          0.252538          0.068074  \n",
       "\n",
       "[43903 rows x 56 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_special = pd.read_csv('ML_test_feature.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_special_2 = test_special.drop('text',axis =1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_len_word</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_tfidf_char_0</th>\n",
       "      <th>nb_tfidf_char_1</th>\n",
       "      <th>nb_tfidf_char_2</th>\n",
       "      <th>nb_tfidf_char_3</th>\n",
       "      <th>nb_tfidf_char_4</th>\n",
       "      <th>nb_tfidf2_char_0</th>\n",
       "      <th>nb_tfidf2_char_1</th>\n",
       "      <th>nb_tfidf2_char_2</th>\n",
       "      <th>nb_tfidf2_char_3</th>\n",
       "      <th>nb_tfidf2_char_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "      <td>456</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.134831</td>\n",
       "      <td>113.250000</td>\n",
       "      <td>456.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.798131</td>\n",
       "      <td>0.135359</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.126683</td>\n",
       "      <td>0.616215</td>\n",
       "      <td>0.207238</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.013397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>221</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.162791</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.991807</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.111529</td>\n",
       "      <td>0.739262</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.066351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>375</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>52.714286</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>0.025597</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.872497</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>150</td>\n",
       "      <td>1218</td>\n",
       "      <td>138</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>4.079167</td>\n",
       "      <td>75.187500</td>\n",
       "      <td>608.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056023</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.881925</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.022749</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.710597</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>510</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>510.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621712</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.191880</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.765081</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>0.029864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>154</td>\n",
       "      <td>98</td>\n",
       "      <td>861</td>\n",
       "      <td>79</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.597403</td>\n",
       "      <td>60.571429</td>\n",
       "      <td>214.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>258</td>\n",
       "      <td>162</td>\n",
       "      <td>1377</td>\n",
       "      <td>155</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4.341085</td>\n",
       "      <td>56.416667</td>\n",
       "      <td>343.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442363</td>\n",
       "      <td>0.067347</td>\n",
       "      <td>0.079578</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.389947</td>\n",
       "      <td>0.046044</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.344736</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.592563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>320</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.423729</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>159.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.975939</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>347</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4.523810</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.925855</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.011098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>710</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.974790</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.020568</td>\n",
       "      <td>0.062242</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.077959</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.067541</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.222341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_words  num_unique_words  num_chars  num_stopwords  num_punct  \\\n",
       "0             89                68        456             54          9   \n",
       "1             43                36        221             25         20   \n",
       "2             64                55        375             34         10   \n",
       "3            240               150       1218            138         28   \n",
       "4             91                71        510             51         13   \n",
       "...          ...               ...        ...            ...        ...   \n",
       "19612        154                98        861             79         29   \n",
       "19613        258               162       1377            155         39   \n",
       "19614         59                44        320             36          9   \n",
       "19615         63                59        347             36         15   \n",
       "19616        119                80        710             63         18   \n",
       "\n",
       "       num_upper_words  num_words_title  mean_len_word           ,      ;  \\\n",
       "0                    5                9       4.134831  113.250000  456.0   \n",
       "1                    5                5       4.162791   26.750000  110.0   \n",
       "2                    0                2       4.875000   52.714286  375.0   \n",
       "3                   11               21       4.079167   75.187500  608.5   \n",
       "4                    4                8       4.615385   84.166667  510.0   \n",
       "...                ...              ...            ...         ...    ...   \n",
       "19612                1               10       4.597403   60.571429  214.5   \n",
       "19613                5               15       4.341085   56.416667  343.5   \n",
       "19614                0                3       4.423729   52.500000  159.5   \n",
       "19615                3                9       4.523810   57.000000  347.0   \n",
       "19616                0                7       4.974790   63.636364  710.0   \n",
       "\n",
       "       ...  nb_tfidf_char_0  nb_tfidf_char_1  nb_tfidf_char_2  \\\n",
       "0      ...         0.047736         0.798131         0.135359   \n",
       "1      ...         0.006369         0.991807         0.000080   \n",
       "2      ...         0.955883         0.025597         0.004314   \n",
       "3      ...         0.056023         0.002947         0.881925   \n",
       "4      ...         0.621712         0.145800         0.032750   \n",
       "...    ...              ...              ...              ...   \n",
       "19612  ...         0.000421         0.999426         0.000000   \n",
       "19613  ...         0.442363         0.067347         0.079578   \n",
       "19614  ...         0.009183         0.989601         0.000757   \n",
       "19615  ...         0.000215         0.995843         0.001813   \n",
       "19616  ...         0.785322         0.020568         0.062242   \n",
       "\n",
       "       nb_tfidf_char_3  nb_tfidf_char_4  nb_tfidf2_char_0  nb_tfidf2_char_1  \\\n",
       "0             0.016439         0.002335          0.126683          0.616215   \n",
       "1             0.000830         0.000914          0.111529          0.739262   \n",
       "2             0.004934         0.009272          0.872497          0.035414   \n",
       "3             0.006078         0.053026          0.022749          0.004354   \n",
       "4             0.191880         0.007858          0.765081          0.092415   \n",
       "...                ...              ...               ...               ...   \n",
       "19612         0.000153         0.000000          0.001873          0.996520   \n",
       "19613         0.020765         0.389947          0.046044          0.012188   \n",
       "19614         0.000460         0.000000          0.014924          0.975939   \n",
       "19615         0.002128         0.000000          0.021312          0.925855   \n",
       "19616         0.053909         0.077959          0.678239          0.025043   \n",
       "\n",
       "       nb_tfidf2_char_2  nb_tfidf2_char_3  nb_tfidf2_char_4  \n",
       "0              0.207238          0.036468          0.013397  \n",
       "1              0.055816          0.027042          0.066351  \n",
       "2              0.027220          0.008513          0.056356  \n",
       "3              0.710597          0.000567          0.261733  \n",
       "4              0.074396          0.038244          0.029864  \n",
       "...                 ...               ...               ...  \n",
       "19612          0.000622          0.000328          0.000658  \n",
       "19613          0.344736          0.004469          0.592563  \n",
       "19614          0.004679          0.001378          0.003080  \n",
       "19615          0.025676          0.016059          0.011098  \n",
       "19616          0.067541          0.006835          0.222341  \n",
       "\n",
       "[19617 rows x 56 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_special_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_len_word</th>\n",
       "      <th>,</th>\n",
       "      <th>;</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_tfidf_char_0</th>\n",
       "      <th>nb_tfidf_char_1</th>\n",
       "      <th>nb_tfidf_char_2</th>\n",
       "      <th>nb_tfidf_char_3</th>\n",
       "      <th>nb_tfidf_char_4</th>\n",
       "      <th>nb_tfidf2_char_0</th>\n",
       "      <th>nb_tfidf2_char_1</th>\n",
       "      <th>nb_tfidf2_char_2</th>\n",
       "      <th>nb_tfidf2_char_3</th>\n",
       "      <th>nb_tfidf2_char_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "      <td>456</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4.134831</td>\n",
       "      <td>113.250000</td>\n",
       "      <td>456.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.798131</td>\n",
       "      <td>0.135359</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.126683</td>\n",
       "      <td>0.616215</td>\n",
       "      <td>0.207238</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.013397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>221</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.162791</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.991807</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.111529</td>\n",
       "      <td>0.739262</td>\n",
       "      <td>0.055816</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.066351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>375</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>52.714286</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>0.025597</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.872497</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>150</td>\n",
       "      <td>1218</td>\n",
       "      <td>138</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>4.079167</td>\n",
       "      <td>75.187500</td>\n",
       "      <td>608.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056023</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.881925</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.022749</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.710597</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>71</td>\n",
       "      <td>510</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>510.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621712</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.032750</td>\n",
       "      <td>0.191880</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.765081</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.074396</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>0.029864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>154</td>\n",
       "      <td>98</td>\n",
       "      <td>861</td>\n",
       "      <td>79</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4.597403</td>\n",
       "      <td>60.571429</td>\n",
       "      <td>214.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>258</td>\n",
       "      <td>162</td>\n",
       "      <td>1377</td>\n",
       "      <td>155</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4.341085</td>\n",
       "      <td>56.416667</td>\n",
       "      <td>343.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442363</td>\n",
       "      <td>0.067347</td>\n",
       "      <td>0.079578</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.389947</td>\n",
       "      <td>0.046044</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.344736</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.592563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>320</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.423729</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>159.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.975939</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>347</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4.523810</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.995843</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.925855</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.011098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>710</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.974790</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.020568</td>\n",
       "      <td>0.062242</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.077959</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.067541</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.222341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_words  num_unique_words  num_chars  num_stopwords  num_punct  \\\n",
       "0             89                68        456             54          9   \n",
       "1             43                36        221             25         20   \n",
       "2             64                55        375             34         10   \n",
       "3            240               150       1218            138         28   \n",
       "4             91                71        510             51         13   \n",
       "...          ...               ...        ...            ...        ...   \n",
       "19612        154                98        861             79         29   \n",
       "19613        258               162       1377            155         39   \n",
       "19614         59                44        320             36          9   \n",
       "19615         63                59        347             36         15   \n",
       "19616        119                80        710             63         18   \n",
       "\n",
       "       num_upper_words  num_words_title  mean_len_word           ,      ;  \\\n",
       "0                    5                9       4.134831  113.250000  456.0   \n",
       "1                    5                5       4.162791   26.750000  110.0   \n",
       "2                    0                2       4.875000   52.714286  375.0   \n",
       "3                   11               21       4.079167   75.187500  608.5   \n",
       "4                    4                8       4.615385   84.166667  510.0   \n",
       "...                ...              ...            ...         ...    ...   \n",
       "19612                1               10       4.597403   60.571429  214.5   \n",
       "19613                5               15       4.341085   56.416667  343.5   \n",
       "19614                0                3       4.423729   52.500000  159.5   \n",
       "19615                3                9       4.523810   57.000000  347.0   \n",
       "19616                0                7       4.974790   63.636364  710.0   \n",
       "\n",
       "       ...  nb_tfidf_char_0  nb_tfidf_char_1  nb_tfidf_char_2  \\\n",
       "0      ...         0.047736         0.798131         0.135359   \n",
       "1      ...         0.006369         0.991807         0.000080   \n",
       "2      ...         0.955883         0.025597         0.004314   \n",
       "3      ...         0.056023         0.002947         0.881925   \n",
       "4      ...         0.621712         0.145800         0.032750   \n",
       "...    ...              ...              ...              ...   \n",
       "19612  ...         0.000421         0.999426         0.000000   \n",
       "19613  ...         0.442363         0.067347         0.079578   \n",
       "19614  ...         0.009183         0.989601         0.000757   \n",
       "19615  ...         0.000215         0.995843         0.001813   \n",
       "19616  ...         0.785322         0.020568         0.062242   \n",
       "\n",
       "       nb_tfidf_char_3  nb_tfidf_char_4  nb_tfidf2_char_0  nb_tfidf2_char_1  \\\n",
       "0             0.016439         0.002335          0.126683          0.616215   \n",
       "1             0.000830         0.000914          0.111529          0.739262   \n",
       "2             0.004934         0.009272          0.872497          0.035414   \n",
       "3             0.006078         0.053026          0.022749          0.004354   \n",
       "4             0.191880         0.007858          0.765081          0.092415   \n",
       "...                ...              ...               ...               ...   \n",
       "19612         0.000153         0.000000          0.001873          0.996520   \n",
       "19613         0.020765         0.389947          0.046044          0.012188   \n",
       "19614         0.000460         0.000000          0.014924          0.975939   \n",
       "19615         0.002128         0.000000          0.021312          0.925855   \n",
       "19616         0.053909         0.077959          0.678239          0.025043   \n",
       "\n",
       "       nb_tfidf2_char_2  nb_tfidf2_char_3  nb_tfidf2_char_4  \n",
       "0              0.207238          0.036468          0.013397  \n",
       "1              0.055816          0.027042          0.066351  \n",
       "2              0.027220          0.008513          0.056356  \n",
       "3              0.710597          0.000567          0.261733  \n",
       "4              0.074396          0.038244          0.029864  \n",
       "...                 ...               ...               ...  \n",
       "19612          0.000622          0.000328          0.000658  \n",
       "19613          0.344736          0.004469          0.592563  \n",
       "19614          0.004679          0.001378          0.003080  \n",
       "19615          0.025676          0.016059          0.011098  \n",
       "19616          0.067541          0.006835          0.222341  \n",
       "\n",
       "[19617 rows x 56 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_special_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtest2 = xgb.DMatrix(test_special_2)\n",
    "y_pred_xgb = pd.DataFrame(XGBmodel.predict(xgtest2, ntree_limit = XGBmodel.best_ntree_limit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_rf = pd.DataFrame(RFmodel.predict_proba(test_special_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = pd.read_csv('LSTM_prop.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_sum = pd.DataFrame(y_pred_rf.values + y_pred_xgb.values + y_pred_lstm) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = all_model_sum.apply(np.argmax, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        2\n",
       "4        0\n",
       "        ..\n",
       "19612    1\n",
       "19613    4\n",
       "19614    1\n",
       "19615    1\n",
       "19616    0\n",
       "Length: 19617, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_sum.apply(np.argmax, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd.get_dummies(submission)).to_csv('submission.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = y_pred_xgb.apply(np.argmax, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4\n",
       "0      0  0  1  0  0\n",
       "1      0  1  0  0  0\n",
       "2      1  0  0  0  0\n",
       "3      0  0  1  0  0\n",
       "4      1  0  0  0  0\n",
       "...   .. .. .. .. ..\n",
       "19612  0  1  0  0  0\n",
       "19613  0  0  0  0  1\n",
       "19614  0  1  0  0  0\n",
       "19615  0  1  0  0  0\n",
       "19616  1  0  0  0  0\n",
       "\n",
       "[19617 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.get_dummies(abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pd.get_dummies(abc)).to_csv('submission_rf.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053653</td>\n",
       "      <td>0.367372</td>\n",
       "      <td>0.544894</td>\n",
       "      <td>0.032296</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.996765</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999179</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.960624</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.015455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.982359</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.999247</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>0.023681</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.970498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.998918</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4\n",
       "0      0.053653  0.367372  0.544894  0.032296  0.001784\n",
       "1      0.001482  0.996765  0.000433  0.000391  0.000929\n",
       "2      0.999179  0.000228  0.000058  0.000154  0.000380\n",
       "3      0.002268  0.019131  0.960624  0.002521  0.015455\n",
       "4      0.982359  0.003993  0.003588  0.009494  0.000566\n",
       "...         ...       ...       ...       ...       ...\n",
       "19612  0.000294  0.999247  0.000073  0.000162  0.000223\n",
       "19613  0.023681  0.002386  0.002358  0.001077  0.970498\n",
       "19614  0.000770  0.998803  0.000146  0.000099  0.000182\n",
       "19615  0.000357  0.998918  0.000489  0.000098  0.000138\n",
       "19616  0.993160  0.001039  0.001599  0.001442  0.002759\n",
       "\n",
       "[19617 rows x 5 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
